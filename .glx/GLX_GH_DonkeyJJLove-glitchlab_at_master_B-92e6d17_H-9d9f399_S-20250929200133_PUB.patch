From 9d9f3998e0740572bb989f534d407e4a821f0bab Mon Sep 17 00:00:00 2001
From: d2j3 <donkeyjjlove@protonmail.com>
Date: Mon, 29 Sep 2025 22:01:31 +0200
Subject: [PATCH] =?UTF-8?q?4=20file(s)=20staged:=20[=CE=94]=20Zakres=20-?=
 =?UTF-8?q?=20files:=204=20(ast=5Fdelta.py,=20ast=5Findex.py,=20git=5Fio.p?=
 =?UTF-8?q?y,=20phi=5Fpsi=5Fbridge.py)=20-=20typ:=20auto=20(pre-diff)?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

[Φ/Ψ] Mozaika (semantyka kodu)
- Align(mean .py): 0.41
- Hint: lokalne dopasowanie; sprawdź sekcje dotkniętych modułów

[AST] Deltas (staged .py)
- S: 829  H: 3158
- uwagi: wartości przybliżone (heurystyki)

[Dokumentacja]
- decyzja: REVIEW

Meta
- Generated-by: pre-diff/AST-mosaic @ 2025-09-29 20:01:32Z

…
---
 analysis/ast_delta.py      | 322 ++++++++++++++++++++++++++++++
 analysis/ast_index.py      | 348 ++++++++++++++++++++++++++++++++
 analysis/git_io.py         | 398 +++++++++++++++++++++++++++++++++++++
 analysis/phi_psi_bridge.py | 315 +++++++++++++++++++++++++++++
 4 files changed, 1383 insertions(+)
 create mode 100644 analysis/ast_delta.py
 create mode 100644 analysis/ast_index.py
 create mode 100644 analysis/git_io.py
 create mode 100644 analysis/phi_psi_bridge.py

diff --git a/analysis/ast_delta.py b/analysis/ast_delta.py
new file mode 100644
index 0000000..6decb6b
--- /dev/null
+++ b/analysis/ast_delta.py
@@ -0,0 +1,322 @@
+# glitchlab/analysis/ast_delta.py
+# ΔAST: porównanie AstSummary base vs head (ΔS/ΔH/ΔZ, per-label add/del/eq)
+# Python 3.9+
+
+from __future__ import annotations
+
+from dataclasses import dataclass, asdict
+from typing import Dict, List, Optional, Tuple
+
+# Lokalne zależności
+try:
+    from .ast_index import AstSummary, ast_summary_of_source, ast_summary_of_rev, ast_summary_of_file
+except Exception as _e:
+    AstSummary = object  # type: ignore
+    def ast_summary_of_source(*a, **k):  # type: ignore
+        raise RuntimeError("ast_index not available")  # pragma: no cover
+    def ast_summary_of_rev(*a, **k):  # type: ignore
+        return None  # pragma: no cover
+    def ast_summary_of_file(*a, **k):  # type: ignore
+        return None  # pragma: no cover
+
+__all__ = [
+    "LabelDelta",
+    "AstDelta",
+    "diff_label_counts",
+    "ast_delta",
+    "delta_from_sources",
+    "delta_of_file_between_revs",
+    "delta_of_local_file",
+    "merge_deltas",
+    "to_jsonable",
+]
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Dataclasses
+# ──────────────────────────────────────────────────────────────────────────────
+
+@dataclass
+class LabelDelta:
+    add: int = 0      # ile etykiet doszło w head vs base (nadwyżka head)
+    delete: int = 0   # ile etykiet ubyło (nadwyżka base)
+    same: int = 0     # ile „wspólnych” (min(base, head))
+
+    @property
+    def total(self) -> int:
+        return self.add + self.delete + self.same
+
+
+@dataclass
+class AstDelta:
+    # id pliku/ident (opcjonalnie)
+    file_path: str
+    base_ref: str
+    head_ref: str
+
+    # skalarne różnice
+    dS: int
+    dH: int
+    dZ: int
+    dalpha: float
+    dbeta: float
+
+    # surowe wartości
+    S_base: int
+    H_base: int
+    Z_base: int
+    alpha_base: float
+    beta_base: float
+
+    S_head: int
+    H_head: int
+    Z_head: int
+    alpha_head: float
+    beta_head: float
+
+    # per-label
+    labels: Dict[str, LabelDelta]
+
+    # meta: liczniki/skrót
+    n_labels_base: int
+    n_labels_head: int
+    changed_labels: int  # liczba etykiet z add>0 lub delete>0
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Główna logika Δ
+# ──────────────────────────────────────────────────────────────────────────────
+
+def diff_label_counts(base_counts: Dict[str, int], head_counts: Dict[str, int]) -> Dict[str, LabelDelta]:
+    """
+    Zwraca słownik etykieta -> LabelDelta(add, delete, same)
+    add    = max(0, head - base)
+    delete = max(0, base - head)
+    same   = min(base, head)
+    """
+    out: Dict[str, LabelDelta] = {}
+    keys = set(base_counts.keys()) | set(head_counts.keys())
+    for k in sorted(keys):
+        b = int(base_counts.get(k, 0))
+        h = int(head_counts.get(k, 0))
+        ld = LabelDelta(
+            add=max(0, h - b),
+            delete=max(0, b - h),
+            same=min(b, h),
+        )
+        out[k] = ld
+    return out
+
+
+def ast_delta(base: AstSummary, head: AstSummary,
+              base_ref: str = "base", head_ref: str = "head") -> AstDelta:
+    """
+    Porównuje dwie struktury AstSummary. Nie robi heurystyk mapowania węzłów —
+    działa na zliczeniach i skalarnych metrykach S/H/Z, α/β.
+    """
+    # per-label
+    labels = diff_label_counts(base.per_label, head.per_label)
+    changed = sum(1 for v in labels.values() if (v.add > 0 or v.delete > 0))
+
+    return AstDelta(
+        file_path=head.file_path if head.file_path else base.file_path,
+        base_ref=str(base_ref),
+        head_ref=str(head_ref),
+
+        dS=int(head.S - base.S),
+        dH=int(head.H - base.H),
+        dZ=int(head.Z - base.Z),
+
+        dalpha=float(head.alpha - base.alpha),
+        dbeta=float(head.beta - base.beta),
+
+        S_base=int(base.S), H_base=int(base.H), Z_base=int(base.Z),
+        alpha_base=float(base.alpha), beta_base=float(base.beta),
+
+        S_head=int(head.S), H_head=int(head.H), Z_head=int(head.Z),
+        alpha_head=float(head.alpha), beta_head=float(head.beta),
+
+        labels=labels,
+
+        n_labels_base=len(base.per_label),
+        n_labels_head=len(head.per_label),
+        changed_labels=int(changed),
+    )
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Wygodne wywołania pomocnicze
+# ──────────────────────────────────────────────────────────────────────────────
+
+def delta_from_sources(base_src: str, head_src: str, file_path: str = "<memory>",
+                       base_ref: str = "base", head_ref: str = "head") -> AstDelta:
+    """
+    Liczy Δ bezpośrednio z dwóch źródeł tekstowych (stringów).
+    """
+    bsum = ast_summary_of_source(base_src, file_path=f"{base_ref}:{file_path}")
+    hsum = ast_summary_of_source(head_src, file_path=f"{head_ref}:{file_path}")
+    return ast_delta(bsum, hsum, base_ref=base_ref, head_ref=head_ref)
+
+
+def delta_of_file_between_revs(path: str, base_rev: str, head_rev: str = "HEAD") -> Optional[AstDelta]:
+    """
+    Liczy Δ dla pliku `path` między dwiema rewizjami gita (base_rev..head_rev).
+    Jeśli plik nie istnieje w którymś z rev – zwraca None (zachowanie konserwatywne).
+    """
+    bsum = ast_summary_of_rev(path, base_rev)
+    hsum = ast_summary_of_rev(path, head_rev)
+    if bsum is None or hsum is None:
+        return None
+    return ast_delta(bsum, hsum, base_ref=base_rev, head_ref=head_rev)
+
+
+def delta_of_local_file(path_base: str, path_head: str,
+                        base_ref: str = "base_file",
+                        head_ref: str = "head_file") -> Optional[AstDelta]:
+    """
+    Δ dla dwóch lokalnych plików (po ścieżce). Jeśli któryś nie istnieje – None.
+    """
+    bsum = ast_summary_of_file(path_base)
+    hsum = ast_summary_of_file(path_head)
+    if bsum is None or hsum is None:
+        return None
+    return ast_delta(bsum, hsum, base_ref=base_ref, head_ref=head_ref)
+
+
+def merge_deltas(deltas: List[AstDelta], file_path: str = "<multi>") -> AstDelta:
+    """
+    Agreguje kilka AstDelta (np. wiele plików) do jednego skrótu.
+    Per-label sumujemy add/delete/same.
+    S/H/Z i α/β – sumy i średnie ważone przez (S+H); referencje sklejone.
+    """
+    if not deltas:
+        raise ValueError("merge_deltas: empty list")
+
+    def w_pair(d: AstDelta) -> Tuple[float, float, float]:
+        w = max(1.0, float(d.S_head + d.H_head))
+        return w, d.alpha_head * w, d.beta_head * w
+
+    # skalarne sumy (Δ)
+    dS = sum(d.dS for d in deltas)
+    dH = sum(d.dH for d in deltas)
+    dZ = sum(d.dZ for d in deltas)
+
+    # α/β – ważone headem
+    W = sum(w_pair(d)[0] for d in deltas)
+    alpha_head_w = sum(w_pair(d)[1] for d in deltas) / max(1.0, W)
+    beta_head_w = sum(w_pair(d)[2] for d in deltas) / max(1.0, W)
+
+    # Base i head (sumy S/H/Z; α/β jako ważone)
+    S_base = sum(d.S_base for d in deltas)
+    H_base = sum(d.H_base for d in deltas)
+    Z_base = sum(d.Z_base for d in deltas)
+    S_head = sum(d.S_head for d in deltas)
+    H_head = sum(d.H_head for d in deltas)
+    Z_head = sum(d.Z_head for d in deltas)
+
+    # α/β base – policzmy podobnie ważone
+    Wb = sum(max(1.0, float(d.S_base + d.H_base)) for d in deltas)
+    alpha_base_w = sum(max(1.0, float(d.S_base + d.H_base)) * d.alpha_base for d in deltas) / max(1.0, Wb)
+    beta_base_w  = sum(max(1.0, float(d.S_base + d.H_base)) * d.beta_base  for d in deltas) / max(1.0, Wb)
+
+    # per-label agregacja
+    labels: Dict[str, LabelDelta] = {}
+    for d in deltas:
+        for k, v in d.labels.items():
+            cur = labels.get(k) or LabelDelta()
+            labels[k] = LabelDelta(
+                add=cur.add + v.add,
+                delete=cur.delete + v.delete,
+                same=cur.same + v.same
+            )
+
+    changed = sum(1 for v in labels.values() if (v.add > 0 or v.delete > 0))
+
+    return AstDelta(
+        file_path=file_path,
+        base_ref=" + ".join(d.base_ref for d in deltas),
+        head_ref=" + ".join(d.head_ref for d in deltas),
+
+        dS=int(dS), dH=int(dH), dZ=int(dZ),
+        dalpha=float(alpha_head_w - alpha_base_w),
+        dbeta=float(beta_head_w - beta_base_w),
+
+        S_base=int(S_base), H_base=int(H_base), Z_base=int(Z_base),
+        alpha_base=float(alpha_base_w), beta_base=float(beta_base_w),
+
+        S_head=int(S_head), H_head=int(H_head), Z_head=int(Z_head),
+        alpha_head=float(alpha_head_w), beta_head=float(beta_head_w),
+
+        labels=labels,
+
+        n_labels_base=0,  # bez sensu łączyć – można pominąć/obliczyć inaczej
+        n_labels_head=0,
+        changed_labels=int(changed),
+    )
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Serializacja (lekka)
+# ──────────────────────────────────────────────────────────────────────────────
+
+def to_jsonable(delta: AstDelta) -> Dict:
+    """
+    Zwraca „płaski” JSON-owalny słownik (label delty rozwinięte).
+    """
+    labels = {k: asdict(v) for k, v in delta.labels.items()}
+    return dict(
+        file_path=delta.file_path,
+        base_ref=delta.base_ref,
+        head_ref=delta.head_ref,
+        dS=delta.dS, dH=delta.dH, dZ=delta.dZ,
+        dalpha=round(delta.dalpha, 6), dbeta=round(delta.dbeta, 6),
+        S_base=delta.S_base, H_base=delta.H_base, Z_base=delta.Z_base,
+        alpha_base=round(delta.alpha_base, 6), beta_base=round(delta.beta_base, 6),
+        S_head=delta.S_head, H_head=delta.H_head, Z_head=delta.Z_head,
+        alpha_head=round(delta.alpha_head, 6), beta_head=round(delta.beta_head, 6),
+        labels=labels,
+        n_labels_base=delta.n_labels_base,
+        n_labels_head=delta.n_labels_head,
+        changed_labels=delta.changed_labels,
+    )
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Minimalne self-testy CLI (opcjonalnie)
+# ──────────────────────────────────────────────────────────────────────────────
+
+def _cli(argv: Optional[List[str]] = None) -> None:
+    """
+    Szybki podgląd:
+      python -m glitchlab.analysis.ast_delta rev PATH baseSHA headSHA
+      python -m glitchlab.analysis.ast_delta file BASE.py HEAD.py
+    """
+    import argparse, json as _json
+    p = argparse.ArgumentParser(prog="ast_delta", description="ΔAST base vs head")
+    sub = p.add_subparsers(dest="cmd", required=True)
+
+    r = sub.add_parser("rev", help="Δ dla pliku między dwiema rewizjami gita")
+    r.add_argument("path")
+    r.add_argument("base_rev")
+    r.add_argument("head_rev")
+
+    f = sub.add_parser("file", help="Δ dla dwóch lokalnych plików")
+    f.add_argument("base_path")
+    f.add_argument("head_path")
+
+    s = sub.add_parser("src", help="Δ dla dwóch źródeł (literałów)")
+    s.add_argument("base_src")
+    s.add_argument("head_src")
+    s.add_argument("--path", default="<memory>")
+
+    args = p.parse_args(argv)
+    if args.cmd == "rev":
+        d = delta_of_file_between_revs(args.path, args.base_rev, args.head_rev)
+    elif args.cmd == "file":
+        d = delta_of_local_file(args.base_path, args.head_path)
+    else:
+        d = delta_from_sources(args.base_src, args.head_src, file_path=args.path)
+
+    if d is None:
+        print(_json.dumps({"ok": False, "error": "file not present in one of revisions/paths"}, indent=2))
+        return
+    print(_json.dumps(to_jsonable(d), ensure_ascii=False, indent=2))
+
+
+if __name__ == "__main__":
+    _cli()
diff --git a/analysis/ast_index.py b/analysis/ast_index.py
new file mode 100644
index 0000000..754bc85
--- /dev/null
+++ b/analysis/ast_index.py
@@ -0,0 +1,348 @@
+# glitchlab/analysis/ast_index.py
+# Deterministyczny indeks AST → AstSummary (bez RNG)
+# Python 3.9+ (stdlib + lokalny import git_io)
+
+from __future__ import annotations
+
+import ast
+import math
+import json
+from dataclasses import dataclass, field
+from pathlib import Path
+from typing import Dict, List, Optional, Tuple
+
+# Lokalny I/O git
+try:
+    from .git_io import show_file_at_rev
+except Exception:  # pozwól na uruchomienie modułu samodzielnie
+    def show_file_at_rev(path: str, rev: str = "HEAD") -> Optional[str]:
+        return None
+
+
+__all__ = [
+    "AstNodeLite",
+    "AstSummary",
+    "ast_summary_of_source",
+    "ast_summary_of_file",
+    "ast_summary_of_rev",
+    "summarize_labels",
+]
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Dataclasses
+# ──────────────────────────────────────────────────────────────────────────────
+
+@dataclass
+class AstNodeLite:
+    """
+    Minimalny węzeł: etykieta + pozycja + głębokość + meta-wektor.
+    meta = [L, S, Sel, Stab, Cau, H]  ∈ [0..1]^6 (deterministycznie z cech)
+    """
+    id: int
+    label: str
+    depth: int
+    parent: Optional[int]
+    lineno: Optional[int]
+    col: Optional[int]
+    children: List[int] = field(default_factory=list)
+    meta: Tuple[float, float, float, float, float, float] = (0, 0, 0, 0, 0, 0)
+
+
+@dataclass
+class AstSummary:
+    """
+    Zbiorcze statystyki AST – kompatybilne polami z warstwą mozaiki.
+    S, H, Z deterministyczne z cech; alpha=S/(S+H), beta=H/(S+H).
+    """
+    file_path: str
+    S: int
+    H: int
+    Z: int
+    maxZ: int
+    alpha: float
+    beta: float
+    nodes: Dict[int, AstNodeLite]
+    labels: List[str]
+    per_label: Dict[str, int]
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Heurystyki/metryki deterministyczne
+# ──────────────────────────────────────────────────────────────────────────────
+
+_CONTROL_NODES = (
+    ast.If, ast.For, ast.While, ast.With, ast.Try, ast.Match
+)
+_DEF_NODES = (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)
+_CALL_NODES = (ast.Call,)
+_DATA_NODES = (ast.Assign, ast.AnnAssign, ast.AugAssign, ast.Return, ast.Yield, ast.YieldFrom)
+_IO_NODES = (ast.Raise, ast.Assert, ast.Global, ast.Nonlocal, ast.Import, ast.ImportFrom, ast.Expr)
+_LEAF_NODES = (ast.Name, ast.Attribute, ast.Constant)
+
+# Wagi wkładu do S/H z typów – wszystkie deterministyczne
+_W_S = {
+    ast.Module: 1,
+    ast.FunctionDef: 3, ast.AsyncFunctionDef: 3, ast.ClassDef: 4,
+    ast.If: 2, ast.For: 3, ast.While: 3, ast.With: 2, ast.Try: 3, ast.Match: 3,
+    ast.Assign: 2, ast.AnnAssign: 2, ast.AugAssign: 2, ast.Return: 1,
+    ast.Call: 1, ast.Import: 1, ast.ImportFrom: 1,
+}
+_W_H = {
+    ast.Name: 1, ast.Attribute: 1, ast.Constant: 1,
+    ast.Call: 3, ast.Assign: 2, ast.AnnAssign: 2, ast.AugAssign: 2,
+    ast.Import: 2, ast.ImportFrom: 2,
+}
+
+
+def _clamp01(x: float) -> float:
+    return 0.0 if x <= 0 else (1.0 if x >= 1.0 else float(x))
+
+
+def _entropy(proportions: List[float]) -> float:
+    """Shannon H na proporcjach etykiet (0..1 z normalizacją)."""
+    ps = [p for p in proportions if p > 0]
+    if not ps:
+        return 0.0
+    H = -sum(p * math.log2(p) for p in ps)
+    Hmax = math.log2(len(ps)) if len(ps) > 1 else 1.0
+    return _clamp01(H / Hmax)
+
+
+def _label_props(labels: List[str]) -> Dict[str, float]:
+    n = max(1, len(labels))
+    counts: Dict[str, int] = {}
+    for l in labels:
+        counts[l] = counts.get(l, 0) + 1
+    return {k: v / n for k, v in counts.items()}
+
+
+def _node_meta(a: ast.AST, depth: int, siblings: int, label_props_global: Dict[str, float]) -> Tuple[float, float, float, float, float, float]:
+    """
+    Deterministyczne meta=[L,S,Sel,Stab,Cau,H]:
+    - L: "liniowość" ~ maleje przy kontrolach/pętlach; rośnie przy liściach
+    - S: udział w strukturze (z wag)
+    - Sel: selektywność ~ duża przy warunkach/wyborach, średnia przy wywołaniach
+    - Stab: stabilność ~ wyższa dla Assign/definicji/stałych; niższa dla Call/Import
+    - Cau: przyczynowość/efekt ~ Call/Return/Assign/Import wysokie
+    - H: zróżnicowanie ~ entropia lokalna (po typie) i głębokość
+    Wszystko skaluje się do [0..1].
+    """
+    # typy uproszczone
+    is_ctrl = isinstance(a, _CONTROL_NODES)
+    is_def = isinstance(a, _DEF_NODES)
+    is_call = isinstance(a, _CALL_NODES)
+    is_data = isinstance(a, _DATA_NODES)
+    is_io = isinstance(a, _IO_NODES)
+    is_leaf = isinstance(a, _LEAF_NODES)
+
+    # L
+    L = 0.75 if is_leaf else (0.35 if is_ctrl else 0.55)
+    # S (normalizowana z wag)
+    s_w = 0
+    for t, w in _W_S.items():
+        if isinstance(a, t):
+            s_w = max(s_w, w)
+    S = _clamp01(s_w / 4.0)
+
+    # Sel
+    if is_ctrl:
+        Sel = 0.8
+    elif is_call:
+        Sel = 0.7
+    elif is_def:
+        Sel = 0.55
+    else:
+        Sel = 0.5
+
+    # Stab
+    if isinstance(a, (ast.Assign, ast.AnnAssign, ast.AugAssign, ast.Constant)):
+        Stab = 0.8
+    elif is_def:
+        Stab = 0.75
+    elif is_call or is_import(a):
+        Stab = 0.45
+    else:
+        Stab = 0.6
+
+    # Cau
+    if is_call or isinstance(a, (ast.Return, ast.Raise, ast.Yield, ast.YieldFrom)):
+        Cau = 0.75
+    elif is_ctrl:
+        Cau = 0.65
+    elif is_def:
+        Cau = 0.6
+    else:
+        Cau = 0.5
+
+    # H – entropia globalna etykiet + korekta głębokością i rozgałęzieniem
+    lbl = a.__class__.__name__
+    p_lbl = label_props_global.get(lbl, 0.0)
+    Hglob = _entropy(list(label_props_global.values()))
+    dep_term = _clamp01(depth / 12.0)
+    sib_term = _clamp01(siblings / 6.0)
+    H = _clamp01(0.6 * Hglob + 0.25 * dep_term + 0.15 * sib_term + 0.05 * (1.0 - p_lbl))
+
+    return (_clamp01(L), _clamp01(Sel), _clamp01(S), _clamp01(Stab), _clamp01(Cau), _clamp01(H))
+
+
+def is_import(a: ast.AST) -> bool:
+    return isinstance(a, (ast.Import, ast.ImportFrom))
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Główne funkcje indeksujące
+# ──────────────────────────────────────────────────────────────────────────────
+
+def ast_summary_of_source(src: str, file_path: str = "<memory>") -> AstSummary:
+    """
+    Parsuje źródło i tworzy deterministyczny AstSummary:
+    - S/H – suma ważona z typów
+    - Z – maksymalna zagnieżdżoność węzłów kontrolnych/def
+    - alpha/beta – normalizacja S/H
+    - nodes – mapa węzłów z meta=[L,S,Sel,Stab,Cau,H]
+    """
+    tree = ast.parse(src, filename=file_path)
+
+    nodes: Dict[int, AstNodeLite] = {}
+    labels: List[str] = []
+    S = H = 0
+    maxZ = 0
+    nid = 0
+
+    # prepass: policz globalne proporcje etykiet (po prostu z surowego DFS)
+    tmp_labels: List[str] = []
+    for _n in ast.walk(tree):
+        tmp_labels.append(_n.__class__.__name__)
+    props = _label_props(tmp_labels)
+
+    def add(a: ast.AST, depth: int, parent: Optional[int]) -> int:
+        nonlocal nid, S, H, maxZ
+        i = nid; nid += 1
+        lbl = a.__class__.__name__
+        # ile dzieci?
+        chs = list(ast.iter_child_nodes(a))
+        siblings = len(chs)
+        # meta
+        L, Sel, Smeta, Stab, Cau, Hmeta = _node_meta(a, depth, siblings, props)
+
+        # akumulacja S/H (z wag deterministycznych)
+        for t, w in _W_S.items():
+            if isinstance(a, t):
+                S += w
+                break
+        for t, w in _W_H.items():
+            if isinstance(a, t):
+                H += w
+                break
+
+        node = AstNodeLite(
+            id=i,
+            label=lbl,
+            depth=depth,
+            parent=parent,
+            lineno=getattr(a, "lineno", None),
+            col=getattr(a, "col_offset", None),
+            meta=(L, Smeta, Sel, Stab, Cau, Hmeta),
+        )
+        nodes[i] = node
+        labels.append(lbl)
+        if parent is not None:
+            nodes[parent].children.append(i)
+
+        # Z – maks. głębokość dla węzłów sterujących/def
+        if isinstance(a, _CONTROL_NODES + _DEF_NODES):
+            maxZ = max(maxZ, depth)
+
+        for ch in chs:
+            add(ch, depth + 1, i)
+        return i
+
+    add(tree, 0, None)
+
+    tot = max(1, S + H)
+    alpha = S / tot
+    beta = H / tot
+    Z = max(1, maxZ)
+    return AstSummary(
+        file_path=file_path,
+        S=int(S),
+        H=int(H),
+        Z=int(Z),
+        maxZ=int(maxZ),
+        alpha=float(alpha),
+        beta=float(beta),
+        nodes=nodes,
+        labels=labels,
+        per_label=summarize_labels(labels),
+    )
+
+
+def ast_summary_of_file(path: str | Path) -> Optional[AstSummary]:
+    p = Path(path)
+    if not p.exists():
+        return None
+    try:
+        src = p.read_text(encoding="utf-8")
+    except UnicodeDecodeError:
+        src = p.read_text(encoding="latin-1", errors="replace")
+    return ast_summary_of_source(src, str(p))
+
+
+def ast_summary_of_rev(path: str, rev: str = "HEAD") -> Optional[AstSummary]:
+    """
+    Pobiera plik z rev:path i zwraca jego AstSummary; gdy brak pliku w rev – None.
+    """
+    src = show_file_at_rev(path, rev)
+    if src is None:
+        return None
+    return ast_summary_of_source(src, f"{rev}:{path}")
+
+
+def summarize_labels(labels: List[str]) -> Dict[str, int]:
+    out: Dict[str, int] = {}
+    for l in labels:
+        out[l] = out.get(l, 0) + 1
+    return out
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Mini-CLI do szybkiego uruchomienia lokalnie
+# ──────────────────────────────────────────────────────────────────────────────
+
+def _cli(argv: Optional[List[str]] = None) -> None:
+    import argparse
+
+    p = argparse.ArgumentParser(prog="ast_index", description="Deterministyczny indeks AST → AstSummary")
+    sub = p.add_subparsers(dest="cmd", required=True)
+
+    q = sub.add_parser("file", help="indeks z lokalnego pliku")
+    q.add_argument("path")
+
+    r = sub.add_parser("rev", help="indeks z gita (rev:path)")
+    r.add_argument("rev")
+    r.add_argument("path")
+
+    args = p.parse_args(argv)
+    if args.cmd == "file":
+        summ = ast_summary_of_file(args.path)
+    else:
+        summ = ast_summary_of_rev(args.path, args.rev)
+
+    if summ is None:
+        print(json.dumps({"ok": False, "error": "file not found in given source"}, indent=2))
+        return
+
+    # Zwięzły JSON (bez pełnych nodes, żeby nie zalewać konsoli)
+    payload = dict(
+        file=summ.file_path,
+        S=summ.S, H=summ.H, Z=summ.Z, maxZ=summ.maxZ,
+        alpha=round(summ.alpha, 4), beta=round(summ.beta, 4),
+        n_nodes=len(summ.nodes),
+        top_labels=sorted(summ.per_label.items(), key=lambda kv: (-kv[1], kv[0]))[:8]
+    )
+    print(json.dumps(payload, ensure_ascii=False, indent=2))
+
+
+if __name__ == "__main__":
+    _cli()
diff --git a/analysis/git_io.py b/analysis/git_io.py
new file mode 100644
index 0000000..e00d84c
--- /dev/null
+++ b/analysis/git_io.py
@@ -0,0 +1,398 @@
+# glitchlab/analysis/git_io.py
+# Git I/O + RepoMosaic (kafel=plik) dla analizy Δ (BASE..HEAD)
+# Python 3.9+ (stdlib only)
+
+from __future__ import annotations
+
+import json
+import os
+import subprocess
+from dataclasses import dataclass, field
+from pathlib import Path
+from typing import Dict, Iterable, List, Optional, Tuple
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Bezpieczne uruchomienie git (cross-platform, bez backticków)
+# ──────────────────────────────────────────────────────────────────────────────
+
+def repo_root(start: Optional[Path] = None) -> Path:
+    """
+    Zwraca korzeń repo (git rev-parse --show-toplevel).
+    Fallback: szuka w górę katalogu .git albo .glx/state.json.
+    """
+    start = Path(start or Path.cwd()).resolve()
+    try:
+        out = subprocess.check_output(
+            ["git", "rev-parse", "--show-toplevel"],
+            cwd=str(start), text=True, stderr=subprocess.DEVNULL
+        ).strip()
+        if out:
+            return Path(out)
+    except Exception:
+        pass
+
+    # fallback: manualny spacer w górę
+    for p in [start, *start.parents]:
+        if (p / ".git").exists() or (p / ".glx" / "state.json").exists():
+            return p
+    return start
+
+
+def _git(args: List[str], cwd: Optional[Path] = None, check: bool = True) -> str:
+    """
+    Uruchamia 'git <args>' i zwraca stdout (text). Przy błędzie – rzuca CalledProcessError.
+    """
+    cwd = cwd or repo_root()
+    res = subprocess.run(["git", *args], cwd=str(cwd),
+                         stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
+    if check and res.returncode != 0:
+        raise subprocess.CalledProcessError(res.returncode, ["git", *args], res.stdout, res.stderr)
+    return res.stdout
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Podstawowe operacje GIT
+# ──────────────────────────────────────────────────────────────────────────────
+
+def git_merge_base(head: str = "HEAD", other: str = "origin/master") -> Optional[str]:
+    """Zwraca sha wspólnego przodka (merge-base). Gdy brak – None."""
+    try:
+        sha = _git(["merge-base", head, other]).strip()
+        return sha or None
+    except subprocess.CalledProcessError:
+        return None
+
+
+def current_branch() -> Optional[str]:
+    """Zwraca nazwę aktualnej gałęzi (lub None np. w detached HEAD)."""
+    try:
+        b = _git(["rev-parse", "--abbrev-ref", "HEAD"]).strip()
+        return b if b and b != "HEAD" else None
+    except subprocess.CalledProcessError:
+        return None
+
+
+def rev_short(rev: str) -> str:
+    """Zwraca skrót 7 znaków dla podanego revision (bez rzucania błędów na brak)."""
+    try:
+        s = _git(["rev-parse", "--short=7", rev]).strip()
+        return s or (rev[:7] if len(rev) >= 7 else rev)
+    except subprocess.CalledProcessError:
+        return rev[:7] if len(rev) >= 7 else rev
+
+
+def list_tracked_files() -> List[str]:
+    """Wszystkie śledzone pliki (git ls-files)."""
+    out = _git(["ls-files"]).splitlines()
+    return [ln.strip() for ln in out if ln.strip()]
+
+
+def changed_files(base: str, head: str = "HEAD",
+                  filters: Optional[Iterable[str]] = None) -> List[str]:
+    """
+    Lista zmienionych ścieżek (A/M/D/R/T) między base..head (git diff --name-status).
+    filters: np. (".py", "glitchlab/") – proste startswith/endswith; None = bez filtra.
+    """
+    args = ["diff", "--name-status", f"{base}..{head}"]
+    out = _git(args).splitlines()
+    paths: List[str] = []
+    for ln in out:
+        if not ln.strip():
+            continue
+        # format: "M\tpath" lub "R100\told\tnew"
+        parts = ln.split("\t")
+        if len(parts) == 2:
+            _, p = parts
+        elif len(parts) == 3:
+            # renames: bierzemy nową ścieżkę
+            _, _, p = parts
+        else:
+            p = parts[-1]
+        p = p.strip()
+        if not p:
+            continue
+        if filters:
+            ok = False
+            for f in filters:
+                if f.startswith("."):
+                    ok |= p.endswith(f)
+                else:
+                    ok |= p.startswith(f)
+            if not ok:
+                continue
+        paths.append(p)
+    return paths
+
+
+def changed_py_files(base: str, head: str = "HEAD") -> List[str]:
+    """Skrót: tylko .py z diffu base..head."""
+    return changed_files(base, head, filters=(".py",))
+
+
+def show_file_at_rev(path: str, rev: str = "HEAD") -> Optional[str]:
+    """
+    Zwraca zawartość pliku z danej rewizji (git show rev:path). Gdy plik nie istniał – None.
+    """
+    try:
+        blob = _git(["show", f"{rev}:{path}"])
+        return blob
+    except subprocess.CalledProcessError:
+        return None
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# GLX state.json (źródło prawdy: base_sha, itp.)
+# ──────────────────────────────────────────────────────────────────────────────
+
+GLX_DIR = ".glx"
+GLX_STATE = "state.json"
+
+
+def _glx_path() -> Path:
+    return repo_root() / GLX_DIR
+
+
+def _glx_state_path() -> Path:
+    return _glx_path() / GLX_STATE
+
+
+def read_glx_state() -> Dict:
+    """
+    Czyta .glx/state.json. Gdy brak – zwraca domyślne pole z base_sha=None.
+    """
+    p = _glx_state_path()
+    if not p.exists():
+        return {"app": "glitchlab", "base_sha": None, "last_seq": "", "branch": current_branch() or "master"}
+    try:
+        return json.loads(p.read_text(encoding="utf-8"))
+    except Exception:
+        # plik uszkodzony: nie blokuj – zwróć minimalny słownik
+        return {"app": "glitchlab", "base_sha": None, "last_seq": "", "branch": current_branch() or "master"}
+
+
+def write_glx_state(state: Dict) -> None:
+    """
+    Zapisuje .glx/state.json (pretty, utf-8). Tworzy katalog .glx jeśli trzeba.
+    """
+    d = _glx_path()
+    d.mkdir(parents=True, exist_ok=True)
+    p = d / GLX_STATE
+    p.write_text(json.dumps(state, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# RepoMosaic = „kafelki plików” (edge/roi jako heurystyki z diff)
+# ──────────────────────────────────────────────────────────────────────────────
+
+@dataclass
+class RepoInfo:
+    root: Path
+    branch: str
+    base_sha: str
+    head_sha: str
+    base7: str
+    head7: str
+
+
+@dataclass
+class RepoMosaic:
+    """
+    Prosty model mozaiki repo dla Φ/Ψ:
+    - files: lista ścieżek (kafli)
+    - edge: „żywość” (0..1) kafla – heurystyka na bazie statusu i rozszerzenia
+    - roi:  kafle „istotne” (np. .py i/lub dotknięte w diff)
+    - layout_rows/cols: propozycja siatki (kwadrat najbliższy N)
+    """
+    files: List[str]
+    edge: List[float]
+    roi: List[float]
+    layout_rows: int
+    layout_cols: int
+    extras: Dict[str, float] = field(default_factory=dict)
+
+
+def _grid_for_n(n: int) -> Tuple[int, int]:
+    """Dobiera (rows, cols) ≈ kwadrat dla n kafli."""
+    if n <= 0:
+        return (1, 1)
+    import math
+    r = int(math.sqrt(n))
+    c = r
+    while r * c < n:
+        c += 1
+        if r * c < n and r < c:
+            r += 1
+    return (r, c)
+
+
+def _edge_score_for_path(path: str, status: str) -> float:
+    """
+    Heurystyka 'edge' (0..1): A/M>R>D, .py > inne, głębokie ścieżki nieco wyżej.
+    """
+    base = {"A": 0.75, "M": 0.70, "R": 0.60, "C": 0.55, "D": 0.50}.get(status[:1], 0.60)
+    if path.endswith(".py"):
+        base += 0.10
+    depth = max(0, path.count(os.sep) - 0)  # im głębiej, tym „bardziej kontekstowe”
+    base += min(0.15, 0.02 * depth)
+    return float(max(0.0, min(1.0, base)))
+
+
+def _roi_flag_for_path(path: str, status: str) -> float:
+    """
+    Heurystyka 'roi' (0/1): .py oraz zmienione (A/M/R/C/D) → 1.0, inaczej 0.0
+    """
+    return 1.0 if path.endswith(".py") and status[:1] in {"A", "M", "R", "C", "D"} else 0.0
+
+
+def _diff_name_status(base: str, head: str) -> List[Tuple[str, str]]:
+    """
+    Zwraca listę (status, path) z git diff --name-status base..head
+    Status przykładowo: 'A', 'M', 'D', 'R100', ...
+    """
+    out = _git(["diff", "--name-status", f"{base}..{head}"]).splitlines()
+    items: List[Tuple[str, str]] = []
+    for ln in out:
+        parts = ln.split("\t")
+        if len(parts) == 2:
+            st, p = parts
+        elif len(parts) == 3:
+            st, _, p = parts
+        else:
+            st, p = parts[0], parts[-1]
+        items.append((st.strip(), p.strip()))
+    return items
+
+
+def build_repo_mosaic(
+    base: Optional[str] = None,
+    head: str = "HEAD",
+    include_unstaged: bool = False
+) -> Tuple[RepoInfo, RepoMosaic, Dict[str, int]]:
+    """
+    Buduje RepoMosaic dla zakresu base..head.
+    - base: gdy None → .glx/state.json:base_sha, w ostateczności merge-base(HEAD, origin/<branch>)
+    - include_unstaged: jeśli True, traktuje 'git diff' jako HEAD + working tree (porównuje z HEAD)
+    Zwraca: (RepoInfo, RepoMosaic, churn_counters)
+    """
+    root = repo_root()
+    branch = current_branch() or "master"
+
+    # HEAD sha
+    try:
+        head_sha = _git(["rev-parse", head]).strip()
+    except subprocess.CalledProcessError:
+        head_sha = head
+
+    # base sha (state → merge-base)
+    st = read_glx_state()
+    base_sha = base or st.get("base_sha")
+    if not base_sha:
+        # spróbuj merge-base z origin/<branch>
+        fallback = git_merge_base("HEAD", f"origin/{branch}")
+        base_sha = fallback or head_sha  # w skrajnym razie (brak zdalnej gałęzi)
+    base7 = rev_short(base_sha)
+    head7 = rev_short(head_sha)
+
+    # nazwy/statusy
+    if include_unstaged:
+        # porównanie HEAD..(working tree) – użyjemy 'git status --porcelain'
+        st_out = _git(["status", "--porcelain"]).splitlines()
+        # mapowanie na status 'M'/'A'/'D' jak najbliższe name-status
+        ns: List[Tuple[str, str]] = []
+        for ln in st_out:
+            ln = ln.strip()
+            if not ln:
+                continue
+            # format: XY path  (X=index, Y=worktree)
+            # bierzemy Y (worktree) gdy różny od ' '
+            if len(ln) < 4:
+                continue
+            X, Y, rest = ln[0], ln[1], ln[3:]
+            status = (Y if Y != " " else X).strip()
+            if status in {"M", "A", "D"}:
+                ns.append((status, rest))
+            else:
+                # sprowadź np. 'R'/'C' itp. do „zmienione”
+                ns.append((status, rest))
+        name_status = ns
+    else:
+        name_status = _diff_name_status(base_sha, head_sha)
+
+    # metryki ruchu
+    churn = {"A": 0, "M": 0, "D": 0, "R": 0, "C": 0, "other": 0}
+    files: List[str] = []
+    edge: List[float] = []
+    roi: List[float] = []
+
+    for st_code, path in name_status:
+        if not path:
+            continue
+        files.append(path)
+        # status bazowy (pierwsza litera)
+        sig = st_code[:1] if st_code else "M"
+        if sig in churn:
+            churn[sig] += 1
+        else:
+            churn["other"] += 1
+        edge.append(_edge_score_for_path(path, st_code))
+        roi.append(_roi_flag_for_path(path, st_code))
+
+    # jeśli brak zmian – użyj śledzonych .py jako kafli „spokojnych”
+    if not files:
+        tracked = [p for p in list_tracked_files() if p.endswith(".py")]
+        files = tracked[:36]  # nie przesadzaj z rozmiarem siatki
+        edge = [0.35 for _ in files]
+        roi = [0.0 for _ in files]
+
+    rows, cols = _grid_for_n(len(files))
+    repoM = RepoMosaic(
+        files=files,
+        edge=edge,
+        roi=roi,
+        layout_rows=rows,
+        layout_cols=cols,
+        extras={}
+    )
+
+    info = RepoInfo(
+        root=root,
+        branch=branch,
+        base_sha=base_sha,
+        head_sha=head_sha,
+        base7=base7,
+        head7=head7
+    )
+    return info, repoM, churn
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# Proste CLI do szybkich testów lokalnych
+# ──────────────────────────────────────────────────────────────────────────────
+
+def _cli(argv: Optional[List[str]] = None) -> None:
+    import argparse
+
+    p = argparse.ArgumentParser(prog="git_io", description="Git I/O + RepoMosaic")
+    p.add_argument("--base", type=str, default=None, help="base sha (domyślnie z .glx/state.json lub merge-base)")
+    p.add_argument("--head", type=str, default="HEAD", help="head rev (domyślnie HEAD)")
+    p.add_argument("--unstaged", action="store_true", help="uwzględnij zmiany w working tree")
+    p.add_argument("--json", action="store_true", help="wypisz JSON (skrót)")
+    args = p.parse_args(argv)
+
+    info, repoM, churn = build_repo_mosaic(base=args.base, head=args.head, include_unstaged=args.unstaged)
+    print(f"[repo] {info.root}  branch={info.branch}  {info.base7}..{info.head7}")
+    print(f"[files] n={len(repoM.files)}  grid={repoM.layout_rows}x{repoM.layout_cols}  churn={churn}")
+    if args.json:
+        payload = dict(
+            repo=dict(root=str(info.root), branch=info.branch, base=info.base7, head=info.head7),
+            files=repoM.files,
+            edge=repoM.edge,
+            roi=repoM.roi,
+            grid=dict(rows=repoM.layout_rows, cols=repoM.layout_cols),
+            churn=churn,
+        )
+        print(json.dumps(payload, ensure_ascii=False, indent=2))
+
+
+if __name__ == "__main__":
+    _cli()
diff --git a/analysis/phi_psi_bridge.py b/analysis/phi_psi_bridge.py
new file mode 100644
index 0000000..614a6e8
--- /dev/null
+++ b/analysis/phi_psi_bridge.py
@@ -0,0 +1,315 @@
+# glitchlab/analysis/policy_phi_psi.py
+# Polityki/latawce Φ/Ψ nad RepoMosaic ↔ AST:
+# - konwersja RepoMosaic → Mosaic (grid)
+# - selektory Φ (balanced/entropy)
+# - Ψ-feedback + sprzężenie (α,β)
+# - zestaw polityk (edge-preserve, roi-stability, diff-budget)
+# - generator raportu commit-note (mosaic/AST)
+#
+# Python 3.9+ (deps: numpy; stdlib only poza importami z naszego projektu)
+
+from __future__ import annotations
+
+import json
+from dataclasses import dataclass, field
+from typing import Callable, Dict, List, Optional, Tuple
+
+import numpy as np
+
+# ── lokalne moduły (1.1 i 1.2) ────────────────────────────────────────────────
+from glitchlab.gui.mosaic.hybrid_ast_mosaic import (
+    Mosaic,
+    build_mosaic,                # nieużywane bezpośrednio; zostawione dla spójności API
+    region_ids,
+    phi_region_for_balanced,
+    phi_region_for_entropy,
+    phi_cost,
+    psi_feedback,
+    couple_alpha_beta,
+    distance_ast_mosaic,
+    ast_deltas,
+    compress_ast,
+    EXAMPLE_SRC,
+    EDGE_THR_DEFAULT,
+    W_DEFAULT,
+)
+
+from glitchlab.analysis.git_io import (
+    RepoMosaic,
+    RepoInfo,
+)
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# 0) Pomocnicze: RepoMosaic → Mosaic (grid)
+# ──────────────────────────────────────────────────────────────────────────────
+
+def repo_mosaic_to_mosaic(R: RepoMosaic) -> Mosaic:
+    """
+    Rzutuje RepoMosaic (kafel = plik) na Mosaic grid używany przez algorytm Φ/Ψ.
+    - edge: z RepoMosaic.edge
+    - roi:  z RepoMosaic.roi
+    - ssim: placeholder (1.0)
+    """
+    rows = max(1, int(R.layout_rows))
+    cols = max(1, int(R.layout_cols))
+    N = rows * cols
+    # jeżeli liczba plików < rows*cols, dopełniamy zerami (stabilne)
+    edge = np.zeros(N, dtype=float)
+    roi = np.zeros(N, dtype=float)
+    ssim = np.ones(N, dtype=float)
+    for i, e in enumerate(R.edge.tolist()):
+        if i >= N:
+            break
+        edge[i] = float(e)
+        roi[i] = float(R.roi[i]) if i < len(R.roi) else 0.0
+    return Mosaic(rows=rows, cols=cols, edge=edge, ssim=ssim, roi=roi, kind="grid")
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# 1) Definicje polityk (latawce)
+# ──────────────────────────────────────────────────────────────────────────────
+
+@dataclass
+class PolicyResult:
+    name: str
+    score: float
+    hints: List[str] = field(default_factory=list)
+    actions: List[str] = field(default_factory=list)   # deklaratywne sugestie
+
+
+@dataclass
+class Policy:
+    name: str
+    fn: Callable[..., PolicyResult]
+
+
+def policy_edge_preserve(M: Mosaic, thr: float = EDGE_THR_DEFAULT) -> PolicyResult:
+    """Edge-preserve: IO/Call/Expr → edges, filtry destruktywne ograniczaj do ~edges."""
+    n_edges = len(region_ids(M, "edges", thr))
+    n_all = M.rows * M.cols
+    p = n_edges / max(1, n_all)
+    # im więcej 'edges', tym ważniejsze rozdzielenie efektów ubocznych (IO) od ROI
+    score = float(min(1.0, 0.5 + 0.5 * p))
+    hints = [
+        f"edges tiles: {n_edges}/{n_all} (p≈{p:.2f})",
+        "Preferuj Call/Expr w warstwie edges; unikaj side-effects w ROI."
+    ]
+    actions = [
+        "Oznacz wywołania IO jako region='edges'.",
+        "Jeśli filtr modyfikuje szeroko, ogranicz region do ~edges lub zastosuj feathering na granicach."
+    ]
+    return PolicyResult("edge_preserve", score, hints, actions)
+
+
+def policy_roi_stability(M: Mosaic, thr: float = EDGE_THR_DEFAULT) -> PolicyResult:
+    """ROI-stability: Assign/Def → roi oraz ~edges; pilnuj stabilizacji stanu."""
+    roi_ids = region_ids(M, "roi", thr)
+    n_roi = len(roi_ids)
+    n_all = M.rows * M.cols
+    p = n_roi / max(1, n_all)
+    # jeżeli ROI jest niewielkie – podbij stabilizację tam i w ~edges
+    score = float(min(1.0, 0.6 + 0.4 * (1.0 - p)))
+    hints = [
+        f"roi tiles: {n_roi}/{n_all} (p≈{p:.2f})",
+        "Stabilizuj stan (Assign/Def) w ROI i ~edges, ogranicz efekt w edges."
+    ]
+    actions = [
+        "Wstaw inicjalizacje stanu (Assign) przed gałęziami decyzyjnymi.",
+        "Reguła: w ROI nie emituj side-effects – preferuj 'return' nad 'print'."
+    ]
+    return PolicyResult("roi_stability", score, hints, actions)
+
+
+def policy_diff_budget(M: Mosaic, thr: float = EDGE_THR_DEFAULT) -> PolicyResult:
+    """
+    Diff-budget: kontrola globalnej zmiany poza ROI.
+    Tu heurystycznie: im większy udział ~edges, tym ciaśniejszy budżet.
+    """
+    n_ne = len(region_ids(M, "~edges", thr))
+    n_all = M.rows * M.cols
+    p = n_ne / max(1, n_all)
+    # im większa strefa spokojna, tym większy nacisk na ograniczenie zmian
+    score = float(min(1.0, 0.4 + 0.6 * p))
+    B = max(0.02, 0.15 - 0.10 * p)  # proponowany budżet MSE poza ROI
+    hints = [
+        f"~edges tiles: {n_ne}/{n_all} (p≈{p:.2f})",
+        f"Proponowany budżet MSE poza ROI: ≤ {B:.3f}",
+    ]
+    actions = [
+        f"Wymuś 'diff-budget' poza ROI ≤ {B:.3f}.",
+        "Jeśli przekroczony → wstaw węzeł kompensujący (Repair) albo rollback."
+    ]
+    return PolicyResult("diff_budget", score, hints, actions)
+
+
+POLICIES: List[Policy] = [
+    Policy("edge_preserve", policy_edge_preserve),
+    Policy("roi_stability", policy_roi_stability),
+    Policy("diff_budget", policy_diff_budget),
+]
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# 2) Analiza Φ/Ψ nad repo: metryki + sugestie
+# ──────────────────────────────────────────────────────────────────────────────
+
+@dataclass
+class AnalysisConfig:
+    edge_thr: float = EDGE_THR_DEFAULT
+    lmbd: float = 0.60         # λ-kompresja AST
+    delta: float = 0.25        # siła Ψ-feedback
+    kappa_ab: float = 0.35     # sprzężenie (α,β)
+    use_entropy_selector: bool = False  # Φ: entropy vs balanced
+
+
+@dataclass
+class AnalysisResult:
+    align: float
+    j_phi: float
+    alpha: float
+    beta: float
+    S: int
+    H: int
+    Z: int
+    policies: List[PolicyResult]
+    commit_note: str
+    details: Dict[str, float]
+
+
+Selector = Callable[[str, Mosaic, float], str]
+
+
+def analyze_repo_ast(
+    repo: RepoMosaic,
+    src_text: Optional[str] = None,
+    cfg: Optional[AnalysisConfig] = None,
+) -> AnalysisResult:
+    """
+    Główna pętla: RepoMosaic → Mosaic → Φ/Ψ → metryki + commit-note.
+    - src_text: jeżeli None, używa EXAMPLE_SRC (placeholder do czasu wpięcia rzeczywistego AST).
+    """
+    cfg = cfg or AnalysisConfig()
+    selector: Selector = (phi_region_for_entropy if cfg.use_entropy_selector else phi_region_for_balanced)
+    M = repo_mosaic_to_mosaic(repo)
+
+    # AST: źródło (na dziś: placeholder lub w przyszłości scalone moduły)
+    src = src_text if src_text is not None else EXAMPLE_SRC
+    ast0 = ast_deltas(src)
+    ast_l = compress_ast(ast0, cfg.lmbd)
+
+    # Koszt Φ (przy wybranym selektorze)
+    J_phi, _ = phi_cost(ast_l, M, cfg.edge_thr, selector=selector)
+
+    # Ψ + sprzężenie (α,β)
+    ast_after = psi_feedback(ast_l, M, cfg.delta, cfg.edge_thr)
+    ast_cpl = couple_alpha_beta(ast_after, M, cfg.edge_thr, delta=cfg.delta, kappa_ab=cfg.kappa_ab)
+
+    align = 1.0 - min(1.0, distance_ast_mosaic(ast_cpl, M, cfg.edge_thr, w=W_DEFAULT))
+
+    # Polityki
+    pol_res: List[PolicyResult] = [p.fn(M, cfg.edge_thr) for p in POLICIES]
+    pol_res.sort(key=lambda pr: pr.score, reverse=True)
+
+    # Commit-note (syntetyczny, pod nasze standardy)
+    note = _render_commit_note(repo, align, J_phi, ast_cpl, pol_res)
+
+    details = dict(
+        Align=align,
+        J_phi=J_phi,
+        alpha=ast_cpl.alpha,
+        beta=ast_cpl.beta,
+        S=float(ast_cpl.S),
+        H=float(ast_cpl.H),
+        Z=float(ast_cpl.Z),
+    )
+
+    return AnalysisResult(
+        align=align,
+        j_phi=J_phi,
+        alpha=ast_cpl.alpha,
+        beta=ast_cpl.beta,
+        S=ast_cpl.S,
+        H=ast_cpl.H,
+        Z=ast_cpl.Z,
+        policies=pol_res,
+        commit_note=note,
+        details=details,
+    )
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# 3) Render commit-note (zgodnie z naszym wzorcem)
+# ──────────────────────────────────────────────────────────────────────────────
+
+def _render_commit_note(repo: RepoMosaic, align: float, j_phi: float,
+                        ast_cpl, pols: List[PolicyResult]) -> str:
+    files_n = len([f for f in repo.files if f])
+    top_pols = pols[:3]
+    pol_lines = []
+    for pr in top_pols:
+        pol_lines.append(f"- {pr.name}: score={pr.score:.2f}")
+        if pr.hints:
+            pol_lines += [f"  • {h}" for h in pr.hints[:2]]
+        if pr.actions:
+            pol_lines += [f"  → {a}" for a in pr.actions[:2]]
+
+    return (
+        f"[Δ] Zakres\n"
+        f"- files: {files_n}\n"
+        f"- typ: analiza Φ/Ψ + polityki (repo-mosaic)\n\n"
+        f"[Φ/Ψ] Mozaika/AST\n"
+        f"- Align(mean): {align:.3f}\n"
+        f"- J_phi(balanced): {j_phi:.4f}\n"
+        f"- α/β: {ast_cpl.alpha:.2f}/{ast_cpl.beta:.2f}\n"
+        f"- AST(S/H/Z): {ast_cpl.S}/{ast_cpl.H}/{ast_cpl.Z}\n\n"
+        f"[Polityki] (top)\n" + "\n".join(pol_lines) + "\n\n"
+        f"[Dokumentacja]\n"
+        f"- decyzja: auto-note (no-op dla docs; tylko raport analityczny)\n\n"
+        f"[Testy / Ryzyko]\n"
+        f"- smoke: analiza off-line (repo snapshot)\n"
+        f"- ryzyko: niskie (bez zmian kodu)\n\n"
+        f"Meta\n"
+        f"- Generated-by: policy_phi_psi (Φ/Ψ + latawce)"
+    )
+
+
+# ──────────────────────────────────────────────────────────────────────────────
+# 4) Proste CLI do lokalnego uruchomienia (np. w hookach)
+# ──────────────────────────────────────────────────────────────────────────────
+
+def cli_main(argv: Optional[List[str]] = None) -> None:
+    import argparse
+    from glitchlab.analysis.git_io import build_repo_mosaic
+
+    p = argparse.ArgumentParser(prog="policy_phi_psi", description="Repo Φ/Ψ + polityki (commit-note)")
+    p.add_argument("--edge-thr", type=float, default=EDGE_THR_DEFAULT)
+    p.add_argument("--lmbd", type=float, default=0.60)
+    p.add_argument("--delta", type=float, default=0.25)
+    p.add_argument("--kappa-ab", type=float, default=0.35)
+    p.add_argument("--entropy", action="store_true", help="użyj selektora Φ(entropy) zamiast balanced")
+    p.add_argument("--export", action="store_true", help="wypisz JSON wyniku")
+    args = p.parse_args(argv)
+
+    info, repo_m, churn = build_repo_mosaic()
+    cfg = AnalysisConfig(
+        edge_thr=args.edge_thr,
+        lmbd=args.lmbd,
+        delta=args.delta,
+        kappa_ab=args.kappa_ab,
+        use_entropy_selector=args.entropy,
+    )
+    res = analyze_repo_ast(repo_m, src_text=None, cfg=cfg)
+
+    print(res.commit_note)
+    if args.export:
+        payload = dict(
+            details=res.details,
+            policies=[dict(name=p.name, score=p.score, hints=p.hints, actions=p.actions) for p in res.policies],
+            note=res.commit_note,
+        )
+        print("\n[JSON]\n" + json.dumps(payload, ensure_ascii=False, indent=2))
+
+
+if __name__ == "__main__":
+    cli_main()
-- 
2.45.1.windows.1

